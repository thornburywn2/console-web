# Aider Architecture Research Report

**Date:** 2026-01-12
**Research Agent:** Claude-Researcher
**Purpose:** Deep analysis of Aider's architecture for adapting patterns to web-based Claude Code management
**Project Context:** Console.web (console-web v2.10.0)

---

## Executive Summary

Aider is a terminal-based AI pair programming tool that demonstrates sophisticated patterns for multi-file editing, codebase mapping, and LLM integration. This research identifies six key architectural components that can be adapted for a web-based Claude Code management platform.

**Key Findings:**
1. **Repository mapping** via tree-sitter provides scalable context management
2. **Multi-model architecture** separates reasoning from editing for efficiency
3. **Edit format abstraction** enables flexible code modification strategies
4. **Automated quality gates** integrate linting/testing into the AI workflow
5. **Git-centric design** treats version control as first-class citizen
6. **Token optimization** through graph-based ranking and dynamic budgeting

---

## 1. Multi-File Editing and Codebase Mapping

### Architecture Overview

Aider's multi-file editing capability is built on a sophisticated **repository mapping system** that creates a condensed view of the entire codebase.

#### Repository Map Core Components

**1. Tree-Sitter Parsing**
- Uses tree-sitter to parse source code into Abstract Syntax Trees (AST)
- Extracts symbol definitions (functions, classes, variables, types)
- Identifies usage and reference locations across files
- Supports 100+ programming languages

**2. Graph-Based Ranking**
- Constructs a dependency graph where files are nodes
- Edges represent dependencies between files
- Uses PageRank-style algorithm to rank code elements by importance
- Prioritizes most critical code for context inclusion

**3. Token Budget Optimization**
- Default allocation: 1,000 tokens for repo map (configurable via `--map-tokens`)
- Uses binary search to fit maximum relevant content within budget
- Dynamically expands map when no files are in active chat (needs full context)
- Adaptive approach balances detail vs. token constraints

**4. Output Format**
```
repo-map/
├── file1.py
│   ├── class UserManager:
│   │   └── def authenticate(username: str, password: str) -> bool:
│   └── def hash_password(password: str) -> str:
└── file2.py
    └── from file1 import UserManager
```

Shows file structure, key symbols, signatures, and dependencies without full implementations.

### Web Platform Adaptation

**For Console.web:**

✅ **Implement Tree-Sitter Integration**
```javascript
// Backend service
class CodebaseMapper {
  constructor(projectPath) {
    this.parser = new TreeSitterParser()
    this.projectPath = projectPath
  }

  async generateRepoMap(tokenBudget = 1000) {
    // 1. Parse all source files with tree-sitter
    const files = await this.getSourceFiles()
    const asts = await Promise.all(files.map(f => this.parser.parse(f)))

    // 2. Extract symbols and dependencies
    const symbols = this.extractSymbols(asts)
    const dependencies = this.buildDependencyGraph(symbols)

    // 3. Rank by importance using PageRank
    const ranked = this.rankByImportance(dependencies)

    // 4. Select top symbols within token budget
    return this.selectTopSymbols(ranked, tokenBudget)
  }
}
```

✅ **Real-time Map Updates via Socket.IO**
```javascript
// Update repo map when files change
io.on('connection', (socket) => {
  socket.on('file-changed', async (file) => {
    const updatedMap = await codebaseMapper.regenerateMapForFile(file)
    socket.emit('repo-map-updated', updatedMap)
  })
})
```

✅ **Visual Dependency Graph UI Component**
```jsx
<DependencyGraphViewer
  repoMap={repoMap}
  highlightFile={currentFile}
  onNodeClick={navigateToFile}
/>
```

**Benefits for Console.web:**
- Provides context-aware code navigation
- Enables intelligent file suggestions for AI sessions
- Visualizes codebase architecture for developers
- Reduces token usage by sending only relevant context

---

## 2. Git Integration Architecture

### Architecture Overview

Aider treats Git as a **first-class citizen** with automatic commit management and comprehensive version control integration.

#### Git Workflow Components

**1. Automatic Repository Detection**
- Detects git repos on startup
- Offers to initialize repo if none exists
- Validates working directory is clean (or prompts for commit)

**2. Automatic Commit Generation**
- Every AI code change gets an automatic commit
- Commit messages generated by weak-model (fast, cost-effective)
- Sends diffs + chat history to LLM for descriptive messages
- Configurable with `--no-auto-commits`, `--no-dirty-commits`, `--no-git`

**3. Pre-commit Hook Integration**
- Supports `--git-commit-verify` flag to run pre-commit hooks
- Default: skips hooks for speed (can be overridden)
- Allows CI/CD integration without blocking workflow

**4. Undo Capability**
- Simple `/undo` command reverts last AI change
- No manual git commands needed
- Leverages git history for safe rollback

**5. Branch and Merge Support**
- Works within any git branch
- Supports standard git workflows (feature branches, PRs)
- Maintains clean commit history for code review

### Web Platform Adaptation

**For Console.web:**

✅ **Git Dashboard Component**
```jsx
<GitDashboard project={project}>
  <AutoCommitToggle enabled={settings.autoCommit} />
  <CommitHistory limit={10} />
  <BranchSelector current={currentBranch} />
  <UndoButton onClick={revertLastChange} />
</GitDashboard>
```

✅ **Automatic Commit Service**
```javascript
class GitCommitService {
  async autoCommit(projectPath, files, chatHistory) {
    // 1. Stage changed files
    await git.add(files)

    // 2. Generate commit message via LLM
    const diff = await git.diff('--staged')
    const message = await this.generateCommitMessage(diff, chatHistory)

    // 3. Commit with generated message
    await git.commit(message)

    // 4. Notify UI via Socket.IO
    io.emit('git-commit-created', { message, files })
  }

  async generateCommitMessage(diff, chatHistory) {
    // Use fast model (e.g., Claude Haiku) for cost efficiency
    return await claudeHaiku.generate({
      prompt: `Based on this diff and chat context, write a descriptive commit message:\n\nDiff:\n${diff}\n\nContext:\n${chatHistory}`
    })
  }
}
```

✅ **Undo/Redo Stack**
```javascript
class ChangeHistory {
  constructor() {
    this.stack = []
  }

  async undo(projectPath) {
    const lastCommit = this.stack.pop()
    await git.reset('HEAD~1') // Soft reset
    return lastCommit
  }

  async redo(projectPath) {
    // Cherry-pick from reflog
  }
}
```

**Benefits for Console.web:**
- Provides safety net for AI changes
- Enables easy rollback of mistakes
- Maintains clean git history for code review
- Reduces friction in AI-assisted development

---

## 3. Context Management for Large Codebases

### Architecture Overview

Aider implements sophisticated **token optimization** to work effectively with large codebases while respecting LLM context window limits.

#### Context Management Strategies

**1. Selective File Inclusion**
- Only sends files explicitly added to chat (`/add <file>`)
- Optionally includes "read-only" files for context (`/read <file>`)
- Distinguishes between editable vs. reference files

**2. Dynamic Repo Map Sizing**
- **Normal mode**: Stays within `--map-tokens` budget (default 1k)
- **Exploration mode**: Expands significantly when no files in chat
- Adapts based on conversation state

**3. Graph-Based Relevance Ranking**
```
1. Build dependency graph (files as nodes, imports as edges)
2. Compute PageRank scores for all files
3. Select highest-ranked files that fit token budget
4. Include full signatures/definitions for selected files
```

**4. Incremental Context Updates**
- Updates repo map incrementally as files change
- Avoids full regeneration on every edit
- Caches parsed ASTs for performance

**5. Multi-Model Strategy**
- **Architect Model**: Sees full repo map, plans solution (reasoning)
- **Editor Model**: Sees only relevant files, makes precise edits (execution)
- Separates high-level reasoning from detailed implementation

### Token Budget Breakdown Example

For a 100k line codebase with Claude 3.5 Sonnet (200k token context):

```
Context Window Allocation:
├── System Prompt: 2,000 tokens
├── Repo Map: 1,000 tokens (adaptive, can expand to 5k)
├── Active Files: 10,000-50,000 tokens (actual code being edited)
├── Chat History: 5,000-20,000 tokens (conversation context)
└── Response Buffer: 4,000 tokens (LLM output space)
```

### Web Platform Adaptation

**For Console.web:**

✅ **Context Budget Visualizer**
```jsx
<ContextBudgetWidget>
  <TokenBar
    total={200000}
    used={45000}
    breakdown={{
      repoMap: 1200,
      activeFiles: 28000,
      chatHistory: 12000,
      systemPrompt: 2000,
      responseBuffer: 4000
    }}
  />
  <OptimizationSuggestions />
</ContextBudgetWidget>
```

✅ **Smart File Selection Service**
```javascript
class ContextOptimizer {
  async selectRelevantFiles(projectPath, query, tokenBudget) {
    // 1. Parse user intent from query
    const intent = await this.analyzeIntent(query)

    // 2. Score all files by relevance
    const repoMap = await codebaseMapper.getRepoMap()
    const scores = this.scoreFilesByRelevance(repoMap, intent)

    // 3. Select top files within budget
    let budget = tokenBudget
    const selected = []

    for (const file of scores.sort((a, b) => b.score - a.score)) {
      const tokens = await this.estimateTokens(file.path)
      if (budget - tokens >= 0) {
        selected.push(file)
        budget -= tokens
      }
    }

    return selected
  }
}
```

✅ **Adaptive Context Strategy**
```javascript
class AdaptiveContext {
  constructor() {
    this.mode = 'normal' // 'normal' | 'exploration'
  }

  async determineMode(sessionState) {
    // Switch to exploration mode if no files added yet
    if (sessionState.activeFiles.length === 0) {
      this.mode = 'exploration'
      return { repoMapTokens: 5000 } // Expanded budget
    }

    // Switch to normal mode once user adds files
    this.mode = 'normal'
    return { repoMapTokens: 1000 } // Standard budget
  }
}
```

**Benefits for Console.web:**
- Works efficiently with codebases of any size
- Provides transparency into token usage
- Enables cost optimization (fewer tokens = lower costs)
- Improves AI response quality by focusing on relevant code

---

## 4. Testing and Linting Automation

### Architecture Overview

Aider integrates **automated quality gates** directly into the AI coding workflow, catching errors immediately and giving the LLM a chance to fix them.

#### Quality Automation Components

**1. Built-in Linter Support**
- Pre-configured linters for popular languages
- Automatically lints files after AI edits
- Customizable via `--lint-cmd <cmd>`
- Disable with `--no-auto-lint`

**2. Test Suite Integration**
- Runs test suite after AI changes via `--test-cmd <cmd>`
- Expects non-zero exit code + stdout/stderr on failure
- Automatically sends test failures back to LLM for fixing
- Enable with `--auto-test` flag

**3. Commands Class Implementation**
```python
class Commands:
  def cmd_lint(self, args, fnames):
    """Lints files in chat or dirty files in repo"""
    files = fnames or self.get_dirty_files()
    result = subprocess.run(self.lint_cmd + files)
    if result.returncode != 0:
      self.send_to_llm(result.stdout)
      return "Fix the linting errors above"
    return "No linting errors"

  def cmd_test(self, args):
    """Runs tests and provides feedback on failures"""
    result = subprocess.run(self.test_cmd)
    if result.returncode != 0:
      self.send_to_llm(result.stdout + result.stderr)
      return "Fix the test failures above"
    return "All tests passed"
```

**4. Error Feedback Loop**
```
1. AI makes code change
2. Aider runs linter/tests automatically
3. If errors detected:
   a. Send error output to LLM
   b. LLM proposes fix
   c. Repeat until errors resolved
4. Commit successful changes
```

**5. Manual Commands**
- `/lint` - Run linter on demand
- `/test` - Run tests on demand
- Useful for explicit quality checks during development

### Web Platform Adaptation

**For Console.web:**

✅ **Quality Gate Dashboard**
```jsx
<QualityGateDashboard>
  <LintingStatus status={lintStatus} errors={lintErrors} />
  <TestingStatus status={testStatus} failures={testFailures} />
  <AutoFixToggle enabled={settings.autoFix} />
  <ManualRunButtons>
    <button onClick={runLinter}>Run Linter</button>
    <button onClick={runTests}>Run Tests</button>
  </ManualRunButtons>
</QualityGateDashboard>
```

✅ **Automated Quality Service**
```javascript
class QualityGateService {
  async validateChange(projectPath, changedFiles) {
    const results = []

    // 1. Run linter
    if (this.settings.autoLint) {
      const lintResult = await this.runLinter(projectPath, changedFiles)
      results.push(lintResult)

      if (!lintResult.success && this.settings.autoFix) {
        await this.sendErrorsToAI(lintResult.errors, 'linting')
      }
    }

    // 2. Run tests
    if (this.settings.autoTest) {
      const testResult = await this.runTests(projectPath)
      results.push(testResult)

      if (!testResult.success && this.settings.autoFix) {
        await this.sendErrorsToAI(testResult.failures, 'testing')
      }
    }

    return results
  }

  async sendErrorsToAI(errors, type) {
    // Send errors back to Claude for fixing
    const fix = await claude.generate({
      prompt: `Fix these ${type} errors:\n\n${errors}`
    })

    // Apply fix and re-validate
    await this.applyFix(fix)
    return await this.validateChange()
  }
}
```

✅ **Error Visualization Component**
```jsx
<ErrorFeedbackLoop>
  <ErrorTimeline attempts={fixAttempts}>
    {attempts.map(attempt => (
      <AttemptCard
        key={attempt.id}
        errors={attempt.errors}
        fix={attempt.proposedFix}
        result={attempt.result}
      />
    ))}
  </ErrorTimeline>
  <AutoFixProgress />
</ErrorFeedbackLoop>
```

**Benefits for Console.web:**
- Catches errors immediately after AI changes
- Reduces debugging time by fixing issues proactively
- Maintains code quality standards automatically
- Provides transparency into quality gate results

---

## 5. LLM Backend Architecture

### Architecture Overview

Aider implements a **multi-model architecture** with flexible backend support, enabling optimal performance across different LLM providers.

#### LLM Integration Components

**1. LiteLLM Integration**
- Uses LiteLLM package for unified API across providers
- Supports OpenAI, Anthropic, Google, local models, and more
- Consistent interface regardless of backend

**2. Multi-Model Strategy**
```
┌─────────────────────────────────────┐
│     User Request                    │
└──────────┬──────────────────────────┘
           │
           ▼
┌─────────────────────────────────────┐
│  Architect Model (Strong Reasoning) │
│  - Claude 3.5 Sonnet               │
│  - OpenAI o1                        │
│  - DeepSeek R1                      │
│                                     │
│  Output: Solution plan              │
└──────────┬──────────────────────────┘
           │
           ▼
┌─────────────────────────────────────┐
│  Editor Model (Fast Execution)      │
│  - Claude 3.5 Sonnet               │
│  - GPT-4o                           │
│  - DeepSeek Chat V3                 │
│                                     │
│  Output: Precise file edits         │
└──────────┬──────────────────────────┘
           │
           ▼
┌─────────────────────────────────────┐
│  Weak Model (Commit Messages)       │
│  - Claude Haiku                     │
│  - GPT-3.5 Turbo                    │
│                                     │
│  Output: Commit message             │
└─────────────────────────────────────┘
```

**3. Model Switching**
- Runtime switching via `/model <model>` command
- Enables experimentation with different models
- Cost optimization by using cheaper models when appropriate

**4. Best-Performing Models (as of 2026)**
- **Top tier**: Claude 3.5 Sonnet, DeepSeek R1, OpenAI o1
- **Strong performance**: GPT-4o, DeepSeek Chat V3, o3-mini
- **Cost-effective**: Claude Haiku, GPT-3.5 Turbo

**5. Local Model Support**
- Ollama integration for local models
- OpenAI-compatible API support
- Privacy-focused deployments

**6. Custom Model Configuration**
- Model-specific prompts optimized for each LLM
- Edit format selection per model (unified diff vs. SEARCH/REPLACE)
- Temperature, max tokens, and other parameters configurable

### Web Platform Adaptation

**For Console.web:**

✅ **Multi-Model Orchestration Service**
```javascript
class ModelOrchestrator {
  constructor() {
    this.models = {
      architect: 'claude-3.5-sonnet',
      editor: 'claude-3.5-sonnet',
      weak: 'claude-haiku-3.5',
    }
  }

  async processRequest(userRequest, context) {
    // 1. Architect phase: High-level planning
    const plan = await this.callArchitect({
      prompt: userRequest,
      repoMap: context.repoMap,
      chatHistory: context.history
    })

    // 2. Editor phase: Precise implementation
    const edits = await this.callEditor({
      plan: plan,
      activeFiles: context.files,
      editFormat: 'unified-diff'
    })

    // 3. Weak model: Generate commit message
    const commitMsg = await this.callWeakModel({
      diff: edits.diff,
      chatHistory: context.history
    })

    return { plan, edits, commitMsg }
  }

  async callArchitect(input) {
    return await this.invoke(this.models.architect, input, {
      temperature: 0.7,
      systemPrompt: 'You are an expert software architect...'
    })
  }

  async callEditor(input) {
    return await this.invoke(this.models.editor, input, {
      temperature: 0.2,
      editFormat: 'unified-diff'
    })
  }

  async callWeakModel(input) {
    return await this.invoke(this.models.weak, input, {
      temperature: 0.5,
      maxTokens: 200
    })
  }
}
```

✅ **Model Selection UI**
```jsx
<ModelConfigPanel>
  <ModelSelector
    role="architect"
    current={models.architect}
    options={availableModels}
    onChange={updateArchitectModel}
  />
  <ModelSelector
    role="editor"
    current={models.editor}
    options={availableModels}
    onChange={updateEditorModel}
  />
  <CostEstimator models={models} />
</ModelConfigPanel>
```

✅ **Provider Abstraction Layer**
```javascript
class LLMProvider {
  constructor(provider, config) {
    this.provider = provider // 'anthropic' | 'openai' | 'ollama'
    this.config = config
  }

  async generate(prompt, options) {
    switch (this.provider) {
      case 'anthropic':
        return await this.callAnthropic(prompt, options)
      case 'openai':
        return await this.callOpenAI(prompt, options)
      case 'ollama':
        return await this.callOllama(prompt, options)
      default:
        throw new Error(`Unsupported provider: ${this.provider}`)
    }
  }

  async callAnthropic(prompt, options) {
    // Anthropic-specific API call
  }
}
```

**Benefits for Console.web:**
- Flexibility to use optimal model for each task
- Cost optimization by using cheaper models when appropriate
- Support for local/private deployments
- Future-proof as new models are released

---

## 6. Edit Formats and Code Modification

### Architecture Overview

Aider uses **multiple edit formats** to instruct LLMs how to modify code, with different formats optimized for different models.

#### Edit Format Types

**1. SEARCH/REPLACE Format (diff/EditBlock)**

Format uses conflict-resolution-like markers:

```
<<<<<<< SEARCH
def old_function(x):
    return x * 2
=======
def new_function(x, multiplier=2):
    """Multiply x by multiplier (default 2)"""
    return x * multiplier
>>>>>>> REPLACE
```

**Benefits:**
- Clear, unambiguous changes
- No line number fragility
- Works well with GPT-4 and Claude models

**2. Unified Diff Format (udiff)**

Simplified unified diff without line numbers:

```
--- file.py
+++ file.py
@@ @@
-def old_function(x):
-    return x * 2
+def new_function(x, multiplier=2):
+    """Multiply x by multiplier (default 2)"""
+    return x * multiplier
```

**Benefits:**
- Efficient (only returns changed parts)
- Reduces "lazy coding" by 3X for GPT-4 Turbo
- Familiar format for developers

**3. Whole-File Format**

Sends entire file content with changes:

```
file.py:
def new_function(x, multiplier=2):
    """Multiply x by multiplier (default 2)"""
    return x * multiplier

def other_function():
    pass
```

**Benefits:**
- Simple for small files
- No formatting complexity
- Good for initial file creation

#### Model-Specific Optimization

```
Model Recommendations:
├── Claude 3.5 Sonnet → SEARCH/REPLACE
├── GPT-4o → SEARCH/REPLACE
├── GPT-4 Turbo → Unified Diff (reduces laziness)
├── DeepSeek → SEARCH/REPLACE
└── Local models → Whole-File (simpler)
```

#### Performance Impact

**Benchmark results (from Aider blog):**
- GPT-4 Turbo baseline (SEARCH/REPLACE): 20% success rate
- GPT-4 Turbo with unified diff: 61% success rate
- **3X improvement** in reducing lazy coding

### Web Platform Adaptation

**For Console.web:**

✅ **Edit Format Abstraction**
```javascript
class EditFormatManager {
  constructor(model) {
    this.model = model
    this.format = this.selectOptimalFormat(model)
  }

  selectOptimalFormat(model) {
    const formatMap = {
      'claude-3.5-sonnet': 'search-replace',
      'gpt-4o': 'search-replace',
      'gpt-4-turbo': 'unified-diff',
      'deepseek-chat': 'search-replace',
      'ollama': 'whole-file'
    }
    return formatMap[model] || 'search-replace'
  }

  formatEdit(instruction, fileContent) {
    switch (this.format) {
      case 'search-replace':
        return this.generateSearchReplace(instruction, fileContent)
      case 'unified-diff':
        return this.generateUnifiedDiff(instruction, fileContent)
      case 'whole-file':
        return this.generateWholeFile(instruction, fileContent)
    }
  }

  generateSearchReplace(instruction, fileContent) {
    return {
      format: 'search-replace',
      prompt: `Use this format to edit the file:

<<<<<<< SEARCH
[exact lines to replace]
=======
[new lines]
>>>>>>> REPLACE

${instruction}`,
      fileContent
    }
  }
}
```

✅ **Diff Visualization Component**
```jsx
<DiffViewer
  format={editFormat}
  before={originalCode}
  after={modifiedCode}
  showLineNumbers={true}
  highlightChanges={true}
/>
```

✅ **Edit Validation Service**
```javascript
class EditValidator {
  async validateEdit(edit, originalContent) {
    // 1. Parse edit format
    const parsed = this.parseEdit(edit)

    // 2. Find search blocks in original
    const matches = this.findMatches(parsed.search, originalContent)

    if (matches.length === 0) {
      return {
        valid: false,
        error: 'SEARCH block not found in original file'
      }
    }

    if (matches.length > 1) {
      return {
        valid: false,
        error: 'SEARCH block matches multiple locations'
      }
    }

    // 3. Apply replacement
    const newContent = this.applyReplacement(
      originalContent,
      matches[0],
      parsed.replace
    )

    return {
      valid: true,
      newContent
    }
  }
}
```

**Benefits for Console.web:**
- Model-specific optimization for best results
- Reduces AI errors and hallucinations
- Provides clear visualization of changes
- Validates edits before applying to files

---

## Web-Based Platform Considerations

### Challenges Adapting Aider to Web Platform

**1. Terminal Persistence**
- **Aider**: Direct terminal access, long-running process
- **Console.web**: Browser sessions, WebSocket connections
- **Solution**: tmux + Socket.IO for session persistence

**2. File System Access**
- **Aider**: Direct OS file system access
- **Console.web**: Need file browser, secure file operations
- **Solution**: Server-side file APIs with proper authorization

**3. Real-time Collaboration**
- **Aider**: Single-user terminal sessions
- **Console.web**: Multi-user web platform
- **Solution**: Operational Transform or CRDTs for concurrent editing

**4. Process Management**
- **Aider**: Runs as standalone CLI process
- **Console.web**: Must manage multiple concurrent sessions
- **Solution**: Process isolation, resource quotas, PM2 clustering

### Architecture Recommendations for Console.web

**1. Microservices Architecture**

```
┌─────────────────────────────────────────────────┐
│              Web Frontend (React)               │
│  - Terminal UI (xterm.js)                       │
│  - Code Editor (Monaco)                         │
│  - Repo Map Visualizer                          │
└─────────────┬───────────────────────────────────┘
              │
              ▼
┌─────────────────────────────────────────────────┐
│           API Gateway (Express + Socket.IO)     │
│  - Authentication (Authentik)                   │
│  - Rate limiting                                │
│  - Request routing                              │
└─────────────┬───────────────────────────────────┘
              │
        ┌─────┴─────────────────────────┐
        │                               │
        ▼                               ▼
┌───────────────────┐         ┌────────────────────┐
│  Terminal Service │         │   AI Coding Service│
│  - tmux sessions  │         │   - Model orchestr.│
│  - PTY management │         │   - Edit formats   │
│  - Command hist.  │         │   - Context mgmt.  │
└───────────────────┘         └─────────┬──────────┘
        │                               │
        ▼                               ▼
┌───────────────────┐         ┌────────────────────┐
│  Repo Map Service │         │  Quality Service   │
│  - Tree-sitter    │         │  - Linting         │
│  - Dependency grph│         │  - Testing         │
│  - Token optimiz. │         │  - Auto-fix        │
└───────────────────┘         └────────────────────┘
        │                               │
        └───────────┬───────────────────┘
                    ▼
        ┌───────────────────────┐
        │   Git Service         │
        │   - Auto-commit       │
        │   - History           │
        │   - Undo/redo         │
        └───────────────────────┘
                    │
                    ▼
        ┌───────────────────────┐
        │  PostgreSQL + Prisma  │
        │  - Session data       │
        │  - User preferences   │
        │  - Metrics            │
        └───────────────────────┘
```

**2. Key Components to Build**

✅ **Codebase Mapper Service**
- Tree-sitter parsing for 100+ languages
- PageRank-based file ranking
- Token budget optimization
- Real-time updates via file watchers

✅ **AI Coding Orchestrator**
- Multi-model coordination (architect + editor + weak)
- Edit format selection per model
- Context window management
- Cost tracking and optimization

✅ **Quality Gate Service**
- Automated linting on file changes
- Test suite execution
- Error feedback to AI for auto-fix
- Quality metrics dashboard

✅ **Git Integration Service**
- Auto-commit on AI changes
- LLM-generated commit messages
- Undo/redo stack management
- Branch and merge operations

✅ **Session Manager**
- Persistent tmux sessions
- Socket.IO real-time updates
- Multi-user collaboration support
- Session handoff and sharing

**3. Performance Optimization**

```javascript
// Cache repo maps to avoid regeneration
class RepoMapCache {
  constructor() {
    this.cache = new Map()
    this.ttl = 5 * 60 * 1000 // 5 minutes
  }

  async get(projectPath) {
    const cached = this.cache.get(projectPath)
    if (cached && Date.now() - cached.timestamp < this.ttl) {
      return cached.map
    }

    const map = await codebaseMapper.generate(projectPath)
    this.cache.set(projectPath, { map, timestamp: Date.now() })
    return map
  }

  invalidate(projectPath, changedFiles) {
    // Partial invalidation: only regenerate affected parts
    const cached = this.cache.get(projectPath)
    if (cached) {
      cached.map = this.updatePartial(cached.map, changedFiles)
      cached.timestamp = Date.now()
    }
  }
}
```

**4. Security Considerations**

- **File System Isolation**: Restrict access to project directories only
- **Command Injection**: Sanitize all shell commands
- **Resource Limits**: CPU/memory quotas per session
- **Authentication**: Authentik SSO integration
- **Authorization**: Project-level permissions
- **Audit Logging**: Track all file modifications

---

## Implementation Roadmap for Console.web

### Phase 1: Foundation (Week 1-2)

**Goal:** Core infrastructure for AI-assisted coding

✅ **Tasks:**
1. Set up Codebase Mapper Service with tree-sitter
2. Implement basic repository map generation
3. Create API endpoints for repo map access
4. Build React component for visualizing repo map

**Deliverables:**
- `/api/codebase/map/:project` endpoint
- `<RepoMapViewer>` component
- Token budget calculation

### Phase 2: AI Integration (Week 3-4)

**Goal:** Multi-model AI coding capabilities

✅ **Tasks:**
1. Implement Model Orchestrator Service
2. Add edit format abstraction (SEARCH/REPLACE, unified diff)
3. Create context optimization logic
4. Build Edit Validator Service

**Deliverables:**
- `/api/ai/code` endpoint for AI code generation
- Support for Claude, GPT-4, local models
- Edit format selection based on model
- Context window management

### Phase 3: Quality Gates (Week 5)

**Goal:** Automated testing and linting

✅ **Tasks:**
1. Integrate linting service (ESLint, Prettier, etc.)
2. Add test suite execution
3. Implement error feedback loop to AI
4. Build Quality Gate Dashboard component

**Deliverables:**
- `/api/quality/lint/:project` endpoint
- `/api/quality/test/:project` endpoint
- Auto-fix workflow
- `<QualityGateDashboard>` component

### Phase 4: Git Automation (Week 6)

**Goal:** Seamless version control integration

✅ **Tasks:**
1. Implement Git Service with auto-commit
2. Add LLM-generated commit messages
3. Create undo/redo stack
4. Build Git Dashboard component

**Deliverables:**
- `/api/git/auto-commit` endpoint
- Commit message generation via Claude Haiku
- `/api/git/undo` endpoint
- `<GitDashboard>` component

### Phase 5: Polish & Optimization (Week 7-8)

**Goal:** Performance, UX, and documentation

✅ **Tasks:**
1. Implement repo map caching
2. Add performance metrics tracking
3. Create user documentation
4. Conduct load testing
5. Optimize token usage

**Deliverables:**
- < 1s repo map generation for 100k LOC projects
- User guide for AI-assisted coding features
- Performance benchmarks
- Cost optimization dashboard

---

## Key Takeaways

### What Makes Aider Successful

1. **Context Management**: Intelligent token optimization enables working with large codebases
2. **Multi-Model Strategy**: Separating reasoning from editing improves quality and reduces costs
3. **Git Integration**: Treating version control as first-class citizen provides safety and transparency
4. **Quality Automation**: Integrated linting/testing catches errors early
5. **Edit Format Flexibility**: Model-specific optimizations improve success rates
6. **Tree-Sitter Parsing**: Accurate code understanding across 100+ languages

### Lessons for Console.web

✅ **Do:**
- Implement repository mapping with tree-sitter
- Use multi-model orchestration (architect + editor + weak)
- Integrate quality gates directly into AI workflow
- Provide transparent token budget visualization
- Auto-commit all AI changes with descriptive messages
- Support multiple edit formats per model

❌ **Don't:**
- Send entire codebase to LLM (use selective context)
- Use single model for all tasks (optimize with multi-model)
- Ignore linting/testing errors (provide auto-fix)
- Rely on line numbers for edits (use SEARCH/REPLACE)
- Skip git commits (maintain clean history)
- Hardcode model selection (make it configurable)

### Competitive Advantages for Web Platform

1. **Visual Repo Map**: Interactive dependency graphs (Aider is CLI-only)
2. **Collaboration**: Multi-user sessions, comments, handoffs
3. **Dashboard**: Centralized view of quality metrics, costs, performance
4. **Session Persistence**: Browser-based access to persistent tmux sessions
5. **Integration**: Docker, systemd, monitoring in one interface
6. **Accessibility**: No CLI knowledge required

---

## References & Sources

### Official Documentation
- [Aider - AI Pair Programming in Your Terminal](https://aider.chat/)
- [Aider Documentation](https://aider.chat/docs/)
- [Aider GitHub Repository](https://github.com/Aider-AI/aider)
- [Building a better repository map with tree sitter](https://aider.chat/2023/10/22/repomap.html)
- [Repository map documentation](https://aider.chat/docs/repomap.html)

### Technical Deep Dives
- [Git integration documentation](https://aider.chat/docs/git.html)
- [Linting and testing automation](https://aider.chat/docs/usage/lint-test.html)
- [Connecting to LLMs](https://aider.chat/docs/llms.html)
- [Edit formats documentation](https://aider.chat/docs/more/edit-formats.html)
- [Unified diffs make GPT-4 Turbo 3X less lazy](https://aider.chat/docs/unified-diffs.html)
- [Separating code reasoning and editing](https://aider.chat/2024/09/26/architect.html)

### Community & Reviews
- [Getting Started with Aider: AI-Powered Coding from the Terminal](https://blog.openreplay.com/getting-started-aider-ai-coding-terminal/)
- [Aider Review: A Developer's Month With This Terminal-Based Code Assistant](https://www.blott.com/blog/post/aider-review-a-developers-month-with-this-terminal-based-code-assistant)
- [AI Pair Programming: My Journey with Aider](https://medium.com/@jmoral4/ai-pair-programming-my-journey-with-aider-2aef61394d27)
- [Best AI Coding Agents for 2026: Real-World Developer Reviews](https://www.faros.ai/blog/best-ai-coding-agents-2026)

### Alternative Tools & Comparisons
- [Aider in your browser](https://aider.chat/docs/usage/browser.html)
- [Best Aider Alternatives: AI Code Assistants for Devs in 2025](https://replit.com/discover/aider-alternative)
- [Aider vs Windsurf: Which AI Coding Assistant Should You Choose?](https://uibakery.io/blog/aider-vs-windsurf)

### Research & Implementation Guides
- [Step-by-Step Guide: Refactoring a Large Rust Codebase with aider.dev and Custom LLMs](https://codenotary.com/blog/step-by-step-guide-refactoring-a-large-rust-codebase-with-aiderdev-and-custom-llms)
- [Code Surgery: How AI Assistants Make Precise Edits to Your Files](https://fabianhertwig.com/blog/coding-assistants-file-edits/)
- [RepoMapper - A tool to produce a map of a codebase within a git repository](https://github.com/pdavis68/RepoMapper)

---

## Appendix: Technical Specifications

### Tree-Sitter Language Support

Aider supports 100+ languages via tree-sitter, including:

**Popular Languages:**
- JavaScript/TypeScript, Python, Java, C/C++, C#, Go, Rust
- Ruby, PHP, Swift, Kotlin, Scala, Elixir
- HTML/CSS, SQL, Shell scripts, Markdown

**Query Syntax Example:**
```scheme
; Extract function definitions in Python
(function_definition
  name: (identifier) @function.name
  parameters: (parameters) @function.params
  body: (block) @function.body)
```

### PageRank Algorithm Implementation

**Simplified pseudocode:**

```python
def compute_file_importance(dependency_graph):
    """
    Uses PageRank to rank files by importance in the codebase.

    Args:
        dependency_graph: Dict[str, List[str]] - file -> dependencies

    Returns:
        Dict[str, float] - file -> importance score
    """
    damping_factor = 0.85
    max_iterations = 100
    convergence_threshold = 0.0001

    # Initialize scores
    num_files = len(dependency_graph)
    scores = {file: 1.0 / num_files for file in dependency_graph}

    for _ in range(max_iterations):
        new_scores = {}

        for file in dependency_graph:
            # Base score
            new_score = (1 - damping_factor) / num_files

            # Add contribution from incoming links
            for other_file, dependencies in dependency_graph.items():
                if file in dependencies:
                    new_score += damping_factor * (
                        scores[other_file] / len(dependencies)
                    )

            new_scores[file] = new_score

        # Check convergence
        if max(abs(new_scores[f] - scores[f]) for f in scores) < convergence_threshold:
            break

        scores = new_scores

    return scores
```

### Edit Format Specifications

**SEARCH/REPLACE Format:**
```
<<<<<<< SEARCH
[exact lines to find - must match EXACTLY]
=======
[replacement lines]
>>>>>>> REPLACE
```

**Unified Diff Format (simplified):**
```
--- filename
+++ filename
@@ @@
-[removed line]
+[added line]
 [context line]
```

**Whole-File Format:**
```
filename:
[entire file content with changes]
```

---

**Report Generated:** 2026-01-12 15:09:26 UTC
**Agent:** [AGENT:claude-researcher]
**Total Research Duration:** ~15 minutes
**Sources Consulted:** 25+ web pages, documentation sites, and technical articles
**Next Steps:** Review findings with team, prioritize features for implementation
